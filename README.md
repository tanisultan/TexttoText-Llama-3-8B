# TexttoText-Llama-3-8B
In this project I have use model Llama-3-8B and trained it on dataset of Alpaca. 
<br>
I have use Huggingface TRL's SFTTrainer!.
<br> 
I have done 60 steps to speed things up, but you can set <i>num_train_epochs=1</i> for a full run, and turn off <i>max_steps=None</i>.